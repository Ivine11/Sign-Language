NeRF

深度学习2d驱动 

This challenge comes from the differences between the tokenization and ordering of words in the spoken and sign languages. 

# 手语翻译方法的主要五类：

### 1.Avatar Approaches

### 2.NMT approaches 

Neural machine translation

端到端 上下文关系

#### 2.1神经机器翻译所需基础知识：

RNN，LSTM，GRU等

https://blog.csdn.net/Teng49/article/details/78056517

#### 2.2原理和变种详解-RNN

https://www.jiqizhixin.com/articles/2018-12-14-4

##### 2.2.1经典RNN 

n to n， x和y的长度一样

![image-20220715105700606](/Users/pengruiying/Desktop/Sign-Language/assets/image-20220715105700606.png)

![image-20220715105725400](/Users/pengruiying/Desktop/Sign-Language/assets/image-20220715105725400.png)

![image-20220715105751354](/Users/pengruiying/Desktop/Sign-Language/assets/image-20220715105751354.png)

![image-20220715105817516](/Users/pengruiying/Desktop/Sign-Language/assets/image-20220715105817516.png)

##### 2.2.2 encoder-decoder

也叫seq2seq，是n to m 可以用于机器翻译和（文本摘要，阅读理解，语音识别）

https://blog.csdn.net/deephub/article/details/113778704

将c当做之前的初始状态h0输入到Decoder中

![image-20220715105116463](/Users/pengruiying/Desktop/Sign-Language/assets/image-20220715105116463.png)

将c当做每一步的输入

![image-20220715105306141](/Users/pengruiying/Desktop/Sign-Language/assets/image-20220715105306141.png)

##### 2.2.3 attention

attention is all you need—transformer

李宏毅的seq2seq和transformer

https://arxiv.org/pdf/1706.03762.pdf 

主要改进了decoder部分

![image-20220715105602037](/Users/pengruiying/Desktop/Sign-Language/assets/image-20220715105602037.png)

#### 2.3 LSTM

##### 2.3.1原理

https://colah.github.io/posts/2015-08-Understanding-LSTMs/

维基百科的公式很清楚：

https://en.wikipedia.org/wiki/Long_short-term_memory

#### 2.4 实验-pytorch

官网有很多实验教程，文本分类，文本生成，语言翻译

https://pytorch.org/tutorials/beginner/transformer_tutorial.html

### 3.MG

Motion Graph approches

### 4.Conditional 

#####  1.

一个基于CNN的模型，生成给定语义标签图的摄影图像

a CNN based model to generate photographic images given semantic label maps 16 

##### 2.

基于深度学习的模型，即PixelRNNs，沿两个空间维度依次生成图像像素

 a deep learning-based model, namely PixelRNNs, to sequentially generate the image pixels along the two spatial dimensions 84

##### 3.

一个基于RNN的架构，包括一个编码器和一个解码器网络，用于压缩训练期间呈现的真实图像，并在接收代码后对图像进行精加工

 an RNN-based architecture, including an encoder and a decoder network to compress the real images presented during training and refifine images after receiving codes 33

##### 4.

一个名为StyleGAN的深度生成模型，用于在每个卷积层调整图像风格

a deep generative model, entitled StyleGAN, to adjust the image style at each convolution layer 41-2019

论文：

https://arxiv.org/pdf/1812.04948.pdf

源代码：

https://github.com/NVlabs/stylegan

##### 5.

a model using the combination of GAN and attention mechanism 42

### 5.Other models 

1.Text2sign: Towards sign language production using neural machine translation and generative adversarial networks. *International Journal of Computer Vision*, 128:891–908, 2020. 

NMT&MG + GAN

2.Generation of indian sign language by sentence processing and generative adversarial networks. *In*ternational Conference on Intelligent Sustainable Systems* (ICISS)*, 2020. 



Progressive Transformers (Figure 2b) translate from the symbolic 

domains of gloss or text to continuous sign pose sequences that represent the 

motion of a signer producing a sentence of sign language



# NERF

https://www.matthewtancik.com/nerf